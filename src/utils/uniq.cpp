/* uniq: remove duplicate reads from a file of mapped reads in the
 * dnmtools format (as output from format_reads), based on identical
 * mapping location and alignment to the reference.
 *
 * Copyright (C) 2013-2023 University of Southern California and
 *                         Andrew D. Smith
 *
 * Author: Andrew D. Smith
 *
 * This program is free software: you can redistribute it and/or
 * modify it under the terms of the GNU General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 */

#include <cstdint>  // for [u]int[0-9]+_t
#include <iostream>
#include <random>
#include <stdexcept>
#include <string>
#include <vector>

// generated by autotools
#include <config.h>

#include "GenomicRegion.hpp"
#include "OptionParser.hpp"
#include "bsutils.hpp"
#include "dnmt_error.hpp"
#include "smithlab_os.hpp"
#include "smithlab_utils.hpp"
#include "bam_record_utils.hpp"

using std::cerr;
using std::endl;
using std::ifstream;
using std::ofstream;
using std::runtime_error;
using std::string;
using std::to_string;
using std::vector;

namespace uniq_random {
  // ADS: I made this namespace and functions because different
  // implementations of rand() on different OS meant that even with
  // the same seed, the results could be different. This meant testing
  // didn't work.
  // ADS: (TODO) refactor this
  bool initialized = false;
  std::default_random_engine e;
  std::uniform_int_distribution<int> di;
  void initialize(const size_t the_seed) {
    e = std::default_random_engine(the_seed);
    initialized = true;
  }
  int rand() {
    // ADS: should have same range as ordinary rand() by properties of
    // std::uniform_int_distribution default constructor.
    // assert(initialized);
    return di(e);
  }
}  // namespace uniq_random

struct rd_stats {  // keep track of good bases/reads in and out
  size_t bases{};
  size_t reads{};
  void update(const bam_rec &b) {
    bases += get_l_qseq(b);
    ++reads;
  }
};

static void
write_stats_output(const rd_stats &rs_in, const rd_stats &rs_out,
                   const size_t reads_duped, const string &statfile) {
  if (!statfile.empty()) {
    const size_t reads_removed = rs_in.reads - rs_out.reads;
    const double non_dup_frac =
      (rs_out.reads - reads_duped) / static_cast<double>(rs_in.reads);
    const double dup_rate =
      (reads_removed + reads_duped) / static_cast<double>(reads_duped);
    ofstream out_stat(statfile);
    if (!out_stat) throw runtime_error("bad stats output file");
    out_stat << "total_reads: " << rs_in.reads << endl
             << "total_bases: " << rs_in.bases << endl
             << "unique_reads: " << rs_out.reads << endl
             << "unique_read_bases: " << rs_out.bases << endl
             << "non_duplicate_fraction: " << non_dup_frac << endl
             << "duplicate_reads: " << reads_duped << endl
             << "reads_removed: " << reads_removed << endl
             << "duplication_rate: " << dup_rate << endl;
  }
}

static void
write_hist_output(const vector<size_t> &hist, const string &histfile) {
  if (!histfile.empty()) {
    ofstream out_hist(histfile);
    if (!out_hist) throw runtime_error("bad hist output file");
    for (size_t i = 0; i < hist.size(); ++i)
      if (hist[i] > 0) out_hist << i << '\t' << hist[i] << '\n';
  }
}

/* The "inner" buffer corresponds to all reads sharing chrom, start,
   end and strand, and is a contiguous subset of the "outer" buffer
   that shares the same end and strand. */
static void
process_inner_buffer(const bool add_dup_count,
                     const vector<bam_rec>::iterator it,
                     const vector<bam_rec>::iterator jt, bam_header &hdr,
                     bam_outfile &out, rd_stats &rs_out, size_t &reads_duped,
                     vector<size_t> &hist) {
  constexpr char du_tag[2] = {'D', 'U'};
  const size_t n_reads = std::distance(it, jt);
  const size_t selected = uniq_random::rand() % n_reads;

  if (add_dup_count) {
    const int ret = bam_aux_update_int(*(it + selected), du_tag, n_reads);
    if (ret < 0) throw dnmt_error("error adding duplicate count aux field");
  }

  if (!out.write(hdr, *(it + selected)))
    throw runtime_error("failed writing bam record");
  if (hist.size() <= n_reads) hist.resize(n_reads + 1);
  hist[n_reads]++;
  rs_out.update(*(it + selected));
  reads_duped += (n_reads > 1);
}

/* The buffer corresponds to reads sharing the same mapping chromosome
   and start position. These are gathered and then processed together. */
static void
process_buffer(const bool add_dup_count, rd_stats &rs_out, size_t &reads_duped,
               vector<size_t> &hist, vector<bam_rec> &buffer, bam_header &hdr,
               bam_outfile &out) {
  sort(begin(buffer), end(buffer), precedes_by_end_and_strand);
  auto it(begin(buffer));
  auto jt = it + 1;
  for (; jt != end(buffer); ++jt)
    if (!equivalent_end_and_strand(*it, *jt)) {
      process_inner_buffer(add_dup_count, it, jt, hdr, out, rs_out, reads_duped,
                           hist);
      it = jt;
    }
  process_inner_buffer(add_dup_count, it, jt, hdr, out, rs_out, reads_duped,
                       hist);
  buffer.clear();
}

static void
uniq(const bool VERBOSE, const bool add_dup_count, const size_t n_threads,
     const string &cmd, const string &infile, const string &statfile,
     const string &histfile, const bool bam_format, const string &outfile) {
  // values to tabulate stats; no real cost
  rd_stats rs_in, rs_out;
  size_t reads_duped = 0;
  vector<size_t> hist;

  bam_tpool tpool(n_threads);  // outer scope: must be destroyed last
  {
    bam_infile hts(infile);
    bam_header hdr(hts);
    if (!hdr) throw dnmt_error("failed to read header");

    bam_outfile out(outfile, bam_format);
    {
      bam_header hdr_out(hdr);
      if (!hdr_out) throw dnmt_error("failed create header");
      hdr_out.add_pg_line(cmd, "DNMTOOLS", VERSION);
      if (!out.write(hdr_out)) throw dnmt_error("failed to write header");
    }

    if (n_threads > 1) {
      tpool.set_io(hts);
      tpool.set_io(out);
    }

    bam_rec aln;
    if (hts.read(hdr, aln)) {  // valid SAM/BAM can have 0 reads

      rs_in.update(aln);  // update stats for input we just got

      vector<bam_rec> buffer(1, aln);  // select output from this buffer

      // to check that reads are sorted properly
      vector<bool> chroms_seen(get_n_targets(hdr), false);
      int32_t cur_chrom = get_tid(aln);

      while (hts.read(hdr, aln)) {
        rs_in.update(aln);

        // below works because buffer reset at every new chrom
        if (precedes_by_start(aln, buffer[0]))
          throw runtime_error("not sorted: " + get_qname(buffer[0]) + " " +
                              get_qname(aln));

        const int32_t chrom = get_tid(aln);
        if (chrom != cur_chrom) {
          if (chroms_seen[chrom]) throw runtime_error("input not sorted");
          chroms_seen[chrom] = true;
          cur_chrom = chrom;
        }

        if (!equivalent_chrom_and_start(buffer[0], aln))
          process_buffer(add_dup_count, rs_out, reads_duped, hist, buffer, hdr,
                         out);
        buffer.push_back(aln);
      }
      process_buffer(add_dup_count, rs_out, reads_duped, hist, buffer, hdr,
                     out);
    }
  }
  // write any additional output requested
  write_stats_output(rs_in, rs_out, reads_duped, statfile);
  write_hist_output(hist, histfile);
}

int
main_uniq(int argc, const char **argv) {
  try {
    bool VERBOSE = false;

    bool bam_format = false;
    bool add_dup_count = false;
    bool use_stdout = false;

    // ADS: Not recommended to change this seed. It shouldn't matter
    // at all, and we want results to behave as deterministic.
    size_t the_seed = 408;
    string outfile;
    string statfile;
    string histfile;
    size_t n_threads = 1;

    /****************** COMMAND LINE OPTIONS ********************/
    OptionParser opt_parse(strip_path(argv[0]),
                           "program to remove "
                           "duplicate reads from sorted mapped reads",
                           "<in-file> [out-file]", 2);
    opt_parse.add_opt("threads", 't', "number of threads", false, n_threads);
    opt_parse.add_opt("stats", 'S', "statistics output file", false, statfile);
    opt_parse.add_opt("add-count", 'a', "add duplicate counts to reads", false,
                      add_dup_count);
    opt_parse.add_opt("hist", '\0',
                      "histogram output file for library"
                      " complexity analysis",
                      false, histfile);
    opt_parse.add_opt("bam", 'B', "output in BAM format", false, bam_format);
    opt_parse.add_opt("stdout", '\0', "write to standard output", false,
                      use_stdout);
    opt_parse.add_opt("seed", 's', "random seed", false, the_seed);
    opt_parse.add_opt("verbose", 'v', "print more run info", false, VERBOSE);
    opt_parse.set_show_defaults();
    vector<string> leftover_args;
    opt_parse.parse(argc, argv, leftover_args);
    if (opt_parse.about_requested() || opt_parse.help_requested() ||
        leftover_args.empty()) {
      cerr << opt_parse.help_message() << endl
           << opt_parse.about_message() << endl;
      return EXIT_SUCCESS;
    }
    if (opt_parse.option_missing()) {
      cerr << opt_parse.option_missing_message() << endl;
      return EXIT_SUCCESS;
    }
    if ((leftover_args.size() == 1 && !use_stdout) ||
        (leftover_args.size() == 2 && use_stdout)) {
      cerr << opt_parse.help_message() << endl
           << opt_parse.about_message() << endl;
      return EXIT_SUCCESS;
    }
    const string infile(leftover_args.front());
    if (leftover_args.size() == 2 && !use_stdout)
      outfile = leftover_args.back();
    else
      outfile = string("-");  // so htslib can write to stdout
    /****************** END COMMAND LINE OPTIONS *****************/

    // ADS: Random here is because we choose randomly when keeping one
    // among duplicate reads.
    uniq_random::initialize(the_seed);

    std::ostringstream cmd;
    copy(argv, argv + argc, std::ostream_iterator<const char *>(cmd, " "));

    if (VERBOSE)
      cerr << "[output file: " << outfile << "]" << endl
           << "[output format: " << (bam_format ? "B" : "S") << "AM]" << endl
           << "[stats file: " << (statfile.empty() ? "none" : statfile) << "]"
           << endl
           << "[hist file: " << (histfile.empty() ? "none" : histfile) << "]"
           << endl
           << "[add duplicate count: " << (add_dup_count ? "yes" : "no") << "]"
           << endl
           << "[threads requested: " << n_threads << "]" << endl
           << "[command line: \"" << cmd.str() << "\"]" << endl
           << "[random number seed: " << the_seed << "]" << endl;

    uniq(VERBOSE, add_dup_count, n_threads, cmd.str(), infile, statfile,
         histfile, bam_format, outfile);
  }
  catch (const runtime_error &e) {
    cerr << e.what() << endl;
    return EXIT_FAILURE;
  }
  return EXIT_SUCCESS;
}
